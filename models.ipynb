{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/split_data.pickle', 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "    \n",
    "X_train = data[\"X_train\"]\n",
    "X_test = data[\"X_test\"]\n",
    "y_train = data[\"y_train\"]\n",
    "y_test = data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_models.tfkeras import Classifiers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_model(model_name, input_shape=(80,80,1)):\n",
    "  ClsModel, preprocess_input = Classifiers.get(model_name)\n",
    "\n",
    "  # X = preprocess_input(X_train)\n",
    "  # Xt = preprocess_input(X_test)\n",
    "\n",
    "  # build model\n",
    "  base_model = ClsModel(input_shape=input_shape, include_top=False)\n",
    "  x = GlobalAveragePooling2D()(base_model.output)\n",
    "  output = Dense(1, activation='sigmoid')(x)\n",
    "  model = Model(inputs=[base_model.input], outputs=[output])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def benchmark(model, filename='result.pickle', save=True):\n",
    "  y_pred = model.predict(X_test)\n",
    "  fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "  auc_score = auc(fpr, tpr)\n",
    "  print('AUC:', auc_score)\n",
    "  result = {\n",
    "      \"auc\": auc_score,\n",
    "      \"fpr\": fpr,\n",
    "      \"tpr\": tpr,\n",
    "      \"thresholds\": thresholds\n",
    "  }\n",
    "  if save:\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "  plt.plot(fpr, tpr)\n",
    "  plt.title(\"ROC Curve (%s)\" % (filename,))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model_list = [\n",
    "    'vgg16',\n",
    "    'vgg19',\n",
    "    'resnet18',\n",
    "    'resnet34',\n",
    "    'resnet50v2',\n",
    "    'resnet101',\n",
    "    'resnet152',\n",
    "    'resnet50v2',\n",
    "    'resnet101v2',\n",
    "    'resnet152v2',\n",
    "    'resnext50',\n",
    "    'resnext101',\n",
    "    'densenet121',\n",
    "    'densenet169',\n",
    "    'densenet201',\n",
    "    'inceptionv3',\n",
    "    'xception',\n",
    "    'inceptionresnetv2',\n",
    "    'seresnet18',\n",
    "    'seresnet34',\n",
    "    'seresnext50',\n",
    "    'seresnet101',\n",
    "    'seresnet152',\n",
    "    'seresnext50',\n",
    "    'seresnext101',\n",
    "    'senet154',\n",
    "    'nasnetlarge',\n",
    "    'nasnetmobile',\n",
    "    'mobilenet',\n",
    "    'mobilenetv2',\n",
    "]\n",
    "\n",
    "RMSprop = keras.optimizers.RMSprop(learning_rate=1E-3, rho=0.9, epsilon=1E-8)\n",
    "lr = keras.optimizers.schedules.ExponentialDecay(1E-3, 1, 0.92, staircase=True)\n",
    "SGD = keras.optimizers.SGD(learning_rate=lr, momentum=0.0)\n",
    "\n",
    "batch_size = X_train.shape[0]\n",
    "epochs = 1\n",
    "\n",
    "print('Training Models with', batch_size, 'batch size and', epochs, 'epochs')\n",
    "\n",
    "for model_name in model_list:\n",
    "    model_path = 'models/' + model_name + '.h5'\n",
    "    print(model_name, ':', 'model at path', model_path)\n",
    "    if not os.path.isfile(model_path) or True:\n",
    "        try:\n",
    "            model = get_model(model_name)\n",
    "\n",
    "            print(model_name, ':', 'compiling /w RMSprop')\n",
    "            model.compile(optimizer=RMSprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            print(model_name, ':', 'fitting /w RMSprop')\n",
    "            model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "            print(model_name, ':', 'compiling /w SGD')\n",
    "            model.compile(optimizer=SGD, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            print(model_name, ':', 'fitting /w SGD')\n",
    "            model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "            model.save(model_path)\n",
    "            print(model_name, ':', 'saved')\n",
    "        except Exception as err:\n",
    "            print(model_name, ':', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, X_train, y_train, X_test, y_test, input_shape=(80, 80, 1),  batch_size=32, epochs=50):\n",
    "    \n",
    "    RMSprop = keras.optimizers.RMSprop(learning_rate=1E-3, rho=0.9, epsilon=1E-8)\n",
    "    lr = keras.optimizers.schedules.ExponentialDecay(1E-3, 1, 0.92, staircase=True)\n",
    "    SGD = keras.optimizers.SGD(learning_rate=lr, momentum=0.0)\n",
    "\n",
    "\n",
    "    model_path = 'models/' + model_name + '.h5'\n",
    "    print(model_name, ':', 'model at path', model_path)\n",
    "    \n",
    "    model = get_model(model_name, input_shape)\n",
    "\n",
    "    print(model_name, ':', 'compiling /w RMSprop')\n",
    "    model.compile(optimizer=RMSprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(model_name, ':', 'fitting /w RMSprop')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    print(model_name, ':', 'compiling /w SGD')\n",
    "    model.compile(optimizer=SGD, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(model_name, ':', 'fitting /w SGD')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    model.save(model_path)\n",
    "    print(model_name, ':', 'saved')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "resize_method = 'duplicate'\n",
    "\n",
    "ch = 3\n",
    "\n",
    "if resize_method == 'duplicate':\n",
    "    train_shape = tuple(list(X_train.shape[: -1]) + [ch])\n",
    "    X_train_new = np.broadcast_to(X_train, train_shape).copy()\n",
    "    \n",
    "    test_shape = tuple(list(X_test.shape[: -1]) + [ch])\n",
    "    X_test_new = np.broadcast_to(X_test, test_shape).copy()\n",
    "    \n",
    "    print(X_train_new.shape, X_test_new.shape)    \n",
    "\n",
    "train_model('inceptionresnetv2', X_train_new, y_train, X_test_new, y_test, input_shape=X_train_new.shape[1:], batch_size=X_train.shape[0], epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
